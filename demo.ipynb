{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dstorch.utils import random_weight_init\n",
    "from octconv import OctConv2d, OctReLU, OctMaxPool2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading FashionMNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root='./data', \n",
    "                                      train=True,\n",
    "                                      transform=transform,\n",
    "                                      download=True\n",
    "                                      )\n",
    "\n",
    "test_dataset = datasets.FashionMNIST(root='./data', \n",
    "                                     train=False, \n",
    "                                     transform=transform\n",
    "                                     )\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size,            \n",
    "                                           shuffle=True\n",
    "                                           )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OctCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.convs = nn.Sequential(OctConv2d('first', in_channels=1, out_channels=32, kernel_size=3),\n",
    "                                   OctReLU(),\n",
    "                                   OctConv2d('regular', in_channels=32, out_channels=64, kernel_size=3),\n",
    "                                   OctReLU(),\n",
    "                                   OctConv2d('regular', in_channels=64, out_channels=128, kernel_size=3),\n",
    "                                   OctReLU(),\n",
    "                                   OctMaxPool2d(2),\n",
    "                                   OctConv2d('regular', in_channels=128, out_channels=128, kernel_size=3),\n",
    "                                   OctReLU(),\n",
    "                                   OctConv2d('last', in_channels=128, out_channels=128, kernel_size=3),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(2),\n",
    "                                  )\n",
    "        self.fc = nn.Sequential(nn.Linear(6272, 256),\n",
    "                                nn.Dropout(0.5),\n",
    "                                nn.Linear(256, 10)\n",
    "                                )\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, x.size(1) * x.size(2) * x.size(3))\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Instantiate Model and Loss Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OctCNN()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    model = nn.DataParallel(model)\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Start Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500 Loss: 0.362911581993103. Accuracy: 84.900000\n",
      "Iteration: 1000 Loss: 0.31636983156204224. Accuracy: 87.040000\n",
      "Iteration: 1500 Loss: 0.30958276987075806. Accuracy: 89.330000\n",
      "Iteration: 2000 Loss: 0.21788382530212402. Accuracy: 89.420000\n",
      "Iteration: 2500 Loss: 0.18522046506404877. Accuracy: 90.270000\n",
      "Iteration: 3000 Loss: 0.1775389015674591. Accuracy: 90.890000\n",
      "Iteration: 3500 Loss: 0.15970204770565033. Accuracy: 91.020000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_iter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            \n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        num_iter += 1\n",
    "        \n",
    "        if num_iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                if torch.cuda.is_available():\n",
    "                    images, labels = images.cuda(), labels.cuda()\n",
    "                    \n",
    "                images = Variable(images)\n",
    "                \n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().detach().cpu()\n",
    "            \n",
    "            accuracy = 100 * (correct.item() / total)\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {} Loss: {}. Accuracy: {:4f}'.format(num_iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
